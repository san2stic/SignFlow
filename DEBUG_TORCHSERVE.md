# üîç Debug TorchServe Crash Loop

Guide pour identifier pourquoi TorchServe red√©marre en boucle.

---

## üìä Sympt√¥mes Actuels

```
üöÄ Starting TorchServe with device auto-detection...
‚ö†Ô∏è  No GPU detected, using CPU
üîß Configuring TorchServe with CPU
Removing orphan pid file.
[red√©marre imm√©diatement]
```

---

## üîç √âtape 1: Voir les VRAIES Erreurs

J'ai ajout√© `--foreground` au script de d√©marrage pour voir les logs complets.

### Commandes √† ex√©cuter :

```bash
cd ~/Library/Mobile\ Documents/com~apple~CloudDocs/SignFlow

# Arr√™ter
docker compose down

# Rebuild avec --foreground
docker compose build torchserve

# D√©marrer EN PREMIER PLAN (voir les logs)
docker compose up torchserve
```

### Ce Que Vous Devriez Voir :

**‚úÖ Si TorchServe d√©marre correctement :**
```
INFO - Model server started
INFO - Listening on port 8080
```

**‚ùå Si erreur, vous verrez un stack trace Python :**
```
ERROR - [stack trace d√©taill√©]
Traceback (most recent call last):
  File ...
```

**‚Üí Copiez l'erreur compl√®te et je pourrai vous aider**

---

## üß™ √âtape 2: Test avec Docker Run Direct

Pour isoler le probl√®me :

```bash
# Test TorchServe hors Docker Compose
docker run -it --rm \
  -p 8080:8080 \
  -v $(pwd)/backend/torchserve/model-store:/home/model-server/model-store \
  -v $(pwd)/backend/torchserve/config:/home/model-server/config \
  signflow-torchserve \
  /bin/bash

# Puis dans le container :
/home/model-server/start.sh
```

---

## üîÑ √âtape 3: D√©marrer SANS TorchServe

En attendant de r√©soudre le probl√®me, vous pouvez d√©marrer le reste de l'app :

```bash
# D√©marrer tout SAUF TorchServe
docker compose -f docker-compose.yml -f docker-compose.no-torchserve.yml up -d

# V√©rifier
docker compose ps
# TorchServe sera "Up" mais inactif (alpine container)
# Backend, Frontend, DB, Redis, MLflow fonctionnent normalement
```

Le backend utilisera PyTorch direct au lieu de TorchServe.

---

## üêõ Causes Possibles

### 1. Permissions Fichiers

```bash
# V√©rifier permissions model-store
ls -la backend/torchserve/model-store/

# Doit √™tre readable par user 1000
```

**Fix :**
```bash
chmod 755 backend/torchserve/model-store
```

### 2. Config Properties Invalide

```bash
# Tester la config
docker run -it --rm signflow-torchserve \
  cat /home/model-server/config/config.properties
```

**V√©rifier :**
- Pas de caract√®res sp√©ciaux
- Chemins corrects
- Syntaxe valide

### 3. Java Installation

```bash
# V√©rifier Java dans l'image
docker run -it --rm signflow-torchserve java -version
```

**Attendu :**
```
openjdk version "17.x.x"
```

### 4. TorchServe Installation

```bash
# V√©rifier TorchServe
docker run -it --rm signflow-torchserve torchserve --help
```

### 5. Port D√©j√† Utilis√©

```bash
# V√©rifier ports
lsof -i :8080
lsof -i :8081
lsof -i :8082

# Si occup√©s, changer dans docker-compose.yml :
ports:
  - "8090:8080"  # Utiliser 8090 au lieu de 8080
```

---

## üîß Solutions Alternatives

### Option A: TorchServe Image Officielle

Essayez l'image officielle au lieu de notre build :

```yaml
# docker-compose.yml
torchserve:
  image: pytorch/torchserve:latest-cpu  # Image officielle
  # Commentez 'build:'
  volumes:
    - ./backend/torchserve/model-store:/home/model-server/model-store
    - ./backend/torchserve/config:/home/model-server/config/config.properties
  ports:
    - "8080:8080"
    - "8081:8081"
    - "8082:8082"
```

```bash
docker compose up torchserve
```

### Option B: PyTorch Backend Direct (Sans TorchServe)

Le plus simple pour continuer le d√©veloppement :

```bash
# Utiliser docker-compose.no-torchserve.yml
docker compose -f docker-compose.yml -f docker-compose.no-torchserve.yml up -d
```

Le backend FastAPI fera l'inf√©rence directement avec PyTorch.

**Avantages :**
- ‚úÖ Plus simple (pas de .mar √† cr√©er)
- ‚úÖ D√©veloppement plus rapide
- ‚úÖ M√™me performance pour dev local

**Inconv√©nient :**
- ‚ùå Pas de batching automatique
- ‚ùå Pas de m√©triques Prometheus natives

---

## üìã Checklist Debug

Ex√©cutez cette checklist et notez les r√©sultats :

```bash
# 1. Container se build ?
docker compose build torchserve
# ‚úÖ ou ‚ùå

# 2. Start script ex√©cutable ?
docker run --rm signflow-torchserve ls -la /home/model-server/start.sh
# Doit montrer -rwxr-xr-x

# 3. Java fonctionne ?
docker run --rm signflow-torchserve java -version
# Doit afficher version

# 4. TorchServe install√© ?
docker run --rm signflow-torchserve torchserve --version
# Doit afficher version

# 5. Config valide ?
docker run --rm signflow-torchserve \
  cat /home/model-server/config/config.properties
# Doit afficher le fichier

# 6. Model store accessible ?
docker run --rm signflow-torchserve \
  ls -la /home/model-server/model-store/
# Doit lister .gitkeep

# 7. Foreground logs ?
docker compose up torchserve
# Noter l'erreur exacte
```

---

## üÜò Si Rien Ne Marche

Utilisez la config sans TorchServe :

```bash
# 1. Arr√™ter tout
docker compose down

# 2. D√©marrer sans TorchServe
docker compose -f docker-compose.yml -f docker-compose.no-torchserve.yml up -d

# 3. V√©rifier que le reste fonctionne
curl http://localhost:8000/health  # Backend
curl http://localhost:3000         # Frontend (navigateur)
curl http://localhost:5001         # MLflow

# 4. Test inf√©rence backend direct
curl -X POST http://localhost:8000/api/v1/translate \
  -H "Content-Type: application/json" \
  -d '{"landmarks": [[[0.5, 0.5, 0.1]]]}'
```

---

## üì§ Partager pour Aide

Pour obtenir de l'aide, fournir :

```bash
# 1. Logs complets foreground
docker compose up torchserve > torchserve_logs.txt 2>&1
# Ctrl+C apr√®s quelques secondes

# 2. Info syst√®me
docker version > debug_info.txt
docker compose version >> debug_info.txt
uname -a >> debug_info.txt

# 3. Checklist r√©sultats
# Coller les r√©sultats de la checklist ci-dessus
```

---

**Mis √† jour :** 2026-02-16
**Version :** 1.0.0
