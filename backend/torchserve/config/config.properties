# TorchServe Configuration - Multi-Device Support
# Compatible CPU / MPS (Apple Silicon) / CUDA GPU

# API Endpoints
inference_address=http://0.0.0.0:8080
management_address=http://0.0.0.0:8081
metrics_address=http://0.0.0.0:8082

# Model Store
model_store=/home/model-server/model-store
load_models=all

# Performance Tuning
default_workers_per_model=1
job_queue_size=100
async_logging=true
max_request_size=10485760
max_response_size=10485760

# Batch Processing
default_response_timeout=120

# Metrics
enable_metrics_api=true
metrics_format=prometheus
number_of_netty_threads=4
netty_client_threads=4

# Logging
install_py_dep_per_model=true

# CORS
cors_allowed_origin=*
cors_allowed_methods=GET, POST, PUT, DELETE, OPTIONS
cors_allowed_headers=*
